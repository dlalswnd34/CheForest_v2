import requests, time, random
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed
from config import SERVICE_KEY, URLS

# ======================
# 1. API í˜¸ì¶œ í•¨ìˆ˜ (ì¬ì‹œë„ í¬í•¨)
# ======================
def fetch_data(url, perPage=8000, retries=3):
    """í•œ ë‹¬ì¹˜ ë°ì´í„°ë¥¼ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ìˆ˜ì§‘"""
    time.sleep(random.uniform(0.5, 1.5))  # ìŠ¤ë ˆë“œ ì‹œì‘ ë¶„ì‚°
    page, results = 1, []

    while True:
        params = {
            "page": page,
            "perPage": perPage,
            "returnType": "JSON",
            "serviceKey": SERVICE_KEY
        }

        attempt = 0
        while attempt < retries:
            try:
                r = requests.get(url, params=params, timeout=30)
                if r.status_code == 200:
                    data = r.json().get("data", [])
                    if not data:
                        return results
                    results.extend(data)
                    print(f"ğŸ“„ {url.split(':')[-1]} â†’ {page} í˜ì´ì§€ ({len(data)}ê±´)")
                    page += 1
                    time.sleep(1)
                    break
                else:
                    attempt += 1
                    print(f"âš ï¸ ì˜¤ë¥˜ {url} (ì‹œë„ {attempt}/{retries}) â†’ {r.text[:100]}")
                    time.sleep(1)
            except Exception as e:
                attempt += 1
                print(f"âš ï¸ ì˜ˆì™¸ {url} (ì‹œë„ {attempt}/{retries}) â†’ {e}")
                time.sleep(1)
        else:
            # retries ì†Œì§„ â†’ ì¤‘ë‹¨
            break
    return results


# ======================
# 2. ë³‘ë ¬ ìˆ˜ì§‘
# ======================
def collect_all(urls, workers=5, perPage=8000):
    all_data = []
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = [executor.submit(fetch_data, url, perPage) for url in urls]
        for future in as_completed(futures):
            all_data.extend(future.result())
    return all_data


# ======================
# 3. ì œì² ì§€ìˆ˜ ê³„ì‚° í•¨ìˆ˜
# ======================
def compute_seasonal_index(df, label):
    seasonal = (
        df.groupby(["season", "fish"])
        .agg(total_qty=("qty", "sum"),
             total_price=("total_price", "sum"))
        .reset_index()
    )

    # ë¶ˆí•„ìš” í’ˆëª© ì œê±° (ì “ í¬í•¨)
    exclude_keywords = ["ê¸°íƒ€", "ì¡", "ë¥˜", "ì “", "ê°€ê³µ", "ê¹€"]
    seasonal = seasonal[~seasonal["fish"].str.contains("|".join(exclude_keywords))]

    # ë¡œê·¸/ì •ê·œí™”
    seasonal["qty_log"] = np.log1p(seasonal["total_qty"])
    seasonal["price_log"] = np.log1p(seasonal["total_price"])
    seasonal["qty_norm"] = seasonal.groupby("season")["qty_log"].transform(lambda x: x / x.max())
    seasonal["price_norm"] = seasonal.groupby("season")["price_log"].transform(lambda x: x / x.max())

    # ì œì² ì§€ìˆ˜ = 0.8*ìˆ˜ëŸ‰ + 0.2*ê°€ê²©
    seasonal["seasonal_index"] = 0.8 * seasonal["qty_norm"] + 0.2 * seasonal["price_norm"]

    # ìƒìœ„ 30% ì»·
    def filter_top_quantile(group):
        cutoff = group["total_qty"].quantile(0.7)
        return group[group["total_qty"] >= cutoff]

    seasonal_filtered = seasonal.groupby("season", group_keys=False).apply(filter_top_quantile)

    # Top10
    top10 = (
        seasonal_filtered.sort_values(["season", "seasonal_index"], ascending=[True, False])
        .groupby("season")
        .head(10)
    )

    print(f"\n=== {label} ì œì² ì§€ìˆ˜ Top10 ===")
    print(top10[["season", "fish", "total_qty", "total_price", "seasonal_index"]])
    return top10


# ======================
# 4. ì‹¤í–‰
# ======================
if __name__ == "__main__":
    all_data = collect_all(URLS, workers=5, perPage=8000)
    df = pd.DataFrame(all_data)

    # ì»¬ëŸ¼ ì •ë¦¬
    df.rename(columns={
        "ìœ„íŒì¼ì": "date",
        "ìˆ˜ì‚°ë¬¼í‘œì¤€ì½”ë“œëª…": "fish",
        "ì–´ì¢…ìƒíƒœëª…": "state",
        "ë¬¼ëŸ‰(í‚¬ë¡œê·¸ë¨)": "qty",
        "ì´ íŒë§¤ì•¡": "total_price"
    }, inplace=True)

    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df["month"] = df["date"].dt.month
    df["qty"] = pd.to_numeric(df["qty"], errors="coerce")
    df["total_price"] = pd.to_numeric(df["total_price"], errors="coerce")

    season_map = {
        12: "ê²¨ìš¸", 1: "ê²¨ìš¸", 2: "ê²¨ìš¸",
        3: "ë´„", 4: "ë´„", 5: "ë´„",
        6: "ì—¬ë¦„", 7: "ì—¬ë¦„", 8: "ì—¬ë¦„",
        9: "ê°€ì„", 10: "ê°€ì„", 11: "ê°€ì„"
    }
    df["season"] = df["month"].map(season_map)

    # ì œì² ì§€ìˆ˜ ê³„ì‚°
    # top10_hwareo = compute_seasonal_index(df[df["state"] == "í™œì–´"], "í™œì–´")
    # top10_seoneo = compute_seasonal_index(df[df["state"] == "ì„ ì–´"], "ì„ ì–´")
    top10_both = compute_seasonal_index(df[df["state"].isin(["í™œì–´", "ì„ ì–´"])], "í™œì–´+ì„ ì–´")

    # CSV ì €ì¥ (Top10 ê²°ê³¼ë§Œ)
    result = pd.concat([
        # top10_hwareo.assign(category="í™œì–´"),
        # top10_seoneo.assign(category="ì„ ì–´"),
        top10_both.assign(category="í™œì–´+ì„ ì–´")
    ])
    result.to_csv("seasonal_index_top10.csv", index=False, encoding="utf-8-sig")
    print("âœ… ì œì² ì§€ìˆ˜ Top10 CSV ì €ì¥ ì™„ë£Œ!")
